{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]] (1, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]\n",
      " [0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]\n",
      " [0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]\n",
      " [0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]\n",
      " [0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]\n",
      " [0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]\n",
      " [0.20174258 0.37835303 0.30633166 0.6411123  0.17698328 0.43437804\n",
      "  0.01776169 0.94688621]] (7, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 순전파\n",
    "D = 8     # input_size \n",
    "N = 7     # 반복 횟수\n",
    "x = np.random.rand(1,D)\n",
    "print(x,x.shape)     # (1,8)\n",
    "\n",
    "print('-'*70)\n",
    "\n",
    "y = np.repeat(x,N,axis=0)  # 수직(행) 방향, axis=0\n",
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13755782 0.07895582 0.33322873 0.47557111 0.73763113 0.91359252\n",
      "  0.39951853 0.59419715]\n",
      " [0.94250455 0.49850586 0.25929771 0.74046384 0.93811118 0.06106741\n",
      "  0.30435129 0.98298249]\n",
      " [0.92894598 0.11673657 0.89313594 0.8201634  0.82689308 0.56908959\n",
      "  0.19176706 0.84401824]\n",
      " [0.82773417 0.81857911 0.24875482 0.98773671 0.32229478 0.48550033\n",
      "  0.461513   0.80254745]\n",
      " [0.33065102 0.28933369 0.76789343 0.48299828 0.63632562 0.14548341\n",
      "  0.68991635 0.10845651]\n",
      " [0.21040628 0.37244166 0.95776852 0.90652424 0.91714383 0.19002648\n",
      "  0.28885493 0.25518524]\n",
      " [0.50075336 0.36642818 0.88227017 0.03829124 0.62787881 0.57162743\n",
      "  0.22066506 0.61225651]] (7, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[3.87855317 2.54098089 4.34234932 4.45174881 5.00627843 2.93638717\n",
      "  2.55658622 4.19964359]] (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "dy = np.random.rand(N,D)\n",
    "print(dy,dy.shape)  # (7,8)\n",
    "\n",
    "print('-'*70)\n",
    "\n",
    "dx = np.sum(dy,axis=0,keepdims=True) # 수직방향 합, keepdims=True이면 2차원, False면 1차원\n",
    "print(dx,dx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4]])\n",
    "np.sum(a,keepdims=True)   # 2차원 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86760038 -0.72147953 -0.95952631  0.54388987  0.51498001  0.39265621\n",
      "   0.35977288  0.77732518]\n",
      " [ 0.21384386  0.21531284 -2.13145672  1.94585065 -2.05470305  0.06231518\n",
      "  -0.28858813  0.18936996]\n",
      " [ 1.63380579  1.49716979 -0.80335148  0.50021132 -0.53103125  2.28788552\n",
      "  -0.37840056 -2.30763407]\n",
      " [ 0.18690128 -0.27382036 -0.31372364  0.51348446 -0.66544056 -0.91383769\n",
      "   0.12703328 -1.20981157]\n",
      " [ 0.46334813 -0.08154623 -0.35297035  0.69417144  0.616089    0.18513006\n",
      "  -0.49205028  1.21562453]\n",
      " [-0.88387123  0.43094464 -1.61564678  0.30629645 -0.34789028  1.10066702\n",
      "   0.1732179  -0.45423697]\n",
      " [-1.58133267  0.07304664 -0.73559451  1.26445401  0.25578512  0.03435073\n",
      "  -0.41035099  0.42066144]] (7, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[ 0.90029554  1.13962779 -6.91226978  5.7683582  -2.21221101  3.14916704\n",
      "  -0.90936589 -1.36870151]] (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# 순전파\n",
    "\n",
    "D,N = 8, 7\n",
    "x = np.random.randn(N,D)  # (7,8)\n",
    "print(x,x.shape)\n",
    "\n",
    "print('-'*70)\n",
    "\n",
    "y = np.sum(x,axis=0,keepdims=True) \n",
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]] (1, 8)\n",
      "----------------------------------------------------------------------\n",
      "[[0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]\n",
      " [0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]\n",
      " [0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]\n",
      " [0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]\n",
      " [0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]\n",
      " [0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]\n",
      " [0.15031319 0.65803608 0.70298368 0.51084182 0.70096724 0.27526445\n",
      "  0.23301631 0.29596825]] (7, 8)\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "D, N = 8, 7\n",
    "dy = np.random.rand(1,D)\n",
    "print(dy,dy.shape)     # (1,8)\n",
    "\n",
    "print('-'*70)\n",
    "\n",
    "dx = np.repeat(dy,N,axis=0)  # 수직(행) 방향, axis=0\n",
    "print(dx,dx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matmul 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self,W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self,x):         # 순전파\n",
    "        W, = self.params\n",
    "        out = np.dot(x,W)\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):     # 역전파\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout,W.T)\n",
    "        dW = np.dot(self.x.T,dout)\n",
    "        self.grads[0][...] = dw    # 깊은 복사(deep copy)\n",
    "        return dx        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 얕은 복사\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "a = b\n",
    "print(a)\n",
    "id(a) == id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 깊은 복사\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "a[...] = b\n",
    "print(a)\n",
    "id(a) == id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.zeros_like()\n",
    "a = np.arange(12).reshape(3,4)\n",
    "b = np.zeros_like(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시그모이드 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params,self.grads = [],[]\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self,x): \n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = dout * self.out *(1 - self.out)  # sigmoid함수의 미분: y*(1 - y), 공식 도출은 참고서적 참조\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine 계층 : MatMul 노드에 bias를  더한 계층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.params = [W,b]\n",
    "        self.grads = [np.zeors_like(W),np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        W,b = self.params\n",
    "        out = np.dot(x,W) + b\n",
    "        self.x = x\n",
    "        return out    \n",
    "    \n",
    "    def backward(self,dout):\n",
    "        W,b = self.params\n",
    "        dx = np.dot(dout,W.T)\n",
    "        dW = np.dot(self.x.T,dout)\n",
    "        db = np.sum(dout,axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dw\n",
    "        self.grads[1][...] = db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax with Loss 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params,self.grads = [], []\n",
    "        self.y = None    # softmax의 출력 값\n",
    "        self.t = None    # 정답 레이블\n",
    "        \n",
    "    def softmax(self,x):\n",
    "        if x.ndim == 2:\n",
    "            x = x - x.max(axis=1, keepdims=True)\n",
    "            x = np.exp(x)\n",
    "            x /= x.sum(axis=1, keepdims=True)\n",
    "        elif x.ndim == 1:\n",
    "            x = x - np.max(x)\n",
    "            x = np.exp(x) / np.sum(np.exp(x))\n",
    "        return x \n",
    "    \n",
    "    # https://smile2x.tistory.com/entry/softmax-crossentropy-%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC \n",
    "    def cross_entropy_error(self,y, t):  \n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size  # 1e-7은 log(0)으로 무한대가 나오는걸 방지\n",
    "          \n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = self.softmax(x)\n",
    "\n",
    "        # 정답 레이블이 원핫 벡터일 경우 정답의 인덱스로 변환\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        loss = self.cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "     \n",
    "    def backward(self,dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        # dx = (self.y - self.t)/batch_size # 순수 Softmax계층 일경우\n",
    "        \n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inf inf inf]\n",
      "[nan nan nan]\n",
      "[  0 -10 -20]\n",
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-b2248606c354>:3: RuntimeWarning: overflow encountered in exp\n",
      "  print(np.exp(a))    # [inf inf inf]  , 무한대 값, 오버플로우 발생\n",
      "<ipython-input-20-b2248606c354>:4: RuntimeWarning: overflow encountered in exp\n",
      "  x = np.exp(a)/np.sum(np.exp(a))\n",
      "<ipython-input-20-b2248606c354>:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.exp(a)/np.sum(np.exp(a))\n"
     ]
    }
   ],
   "source": [
    "# softmax 구현시에  지수값이 크면 오버플로발생으로 nan이 나오는 것을 방지하기 위해 입력 값의 촤대값을 빼주어 사용한다\n",
    "a = np.array([1010,1000,990])\n",
    "print(np.exp(a))    # [inf inf inf]  , 무한대 값, 오버플로우 발생\n",
    "x = np.exp(a)/np.sum(np.exp(a))\n",
    "print(x)  # [nan nan nan]\n",
    "\n",
    "c = np.max(a)\n",
    "print(a - c)\n",
    "x2 = np.exp(a - c)/np.sum(np.exp(a - c))\n",
    "print(x2)  # [9.99954600e-01 4.53978686e-05 2.06106005e-09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가중치 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률적 경사하강법(Stochastic Gradient Descent)\n",
    "class SGD:\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr = lr     # learning rate,학습율\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr*grad[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    '''\n",
    "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
    "            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)\n",
    "            \n",
    "# https://dalpo0814.tistory.com/29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
