{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import warnings\n",
    "import datetime\n",
    "from math import isnan\n",
    "import os\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 필요한 함수 정의\n",
    "def make_datetime(x):\n",
    "    # string 타입의 Time column을 datetime 타입으로 변경\n",
    "    x     = str(x)\n",
    "    year  = int(x[:4])\n",
    "    month = int(x[4:6])\n",
    "    day   = int(x[6:8])\n",
    "    hour  = int(x[8:10])\n",
    "    #mim  = int(x[10:12])\n",
    "    #sec  = int(x[12:])\n",
    "    return dt.datetime(year, month, day, hour)\n",
    "\n",
    "PATH = './data/'\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------ 전처리된 데이터로 실행 시 2-11부터 실행바랍니다. ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Raw Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. quality_data = 시스템 작동 중 문제 발생 시 측정한 지표들 (2시간동안 12회 수집)\n",
    "2. error_data =  시스템 작동시 시스템 로그 중 상태와 관련있는 로그 수집 (시스템 연결상태 및 강제 리붓 등)\n",
    "3. problem_data = 고객이 실제 불만을 제기한 시점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\"\n",
    "\n",
    "train_quality = pd.read_csv(PATH + 'train_quality_data.csv')\n",
    "train_error = pd.read_csv(PATH + 'train_err_data.csv')\n",
    "train_problem = pd.read_csv(PATH + 'train_problem_data.csv')\n",
    "\n",
    "test_quality = pd.read_csv(PATH + \"test_quality_data.csv\")\n",
    "test_error = pd.read_csv(PATH + \"test_err_data.csv\")\n",
    "submission = pd.read_csv(PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. Data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_quality shape : (828624, 16)\n",
      "train_error shape : (16554663, 6)\n",
      "train_problem shape : (5429, 2)\n",
      "\n",
      "test_quality shape : (747972, 16)\n",
      "test_error shape : (16532648, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_quality shape :\", train_quality.shape)\n",
    "print(\"train_error shape :\", train_error.shape)\n",
    "print(\"train_problem shape :\", train_problem.shape)\n",
    "print()\n",
    "print(\"test_quality shape :\", test_quality.shape)\n",
    "print(\"test_error shape :\", test_error.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Time processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test_error의 time 데이터 중 11월을 벗어나는 데이터가 소량 존재함\n",
    "* train_error에는 존재하지 않는 시점이므로 시점통일을 위해 제거해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_processing(raw_df):\n",
    "    df = raw_df.copy()\n",
    "    start_date = datetime.datetime(2020,11,1)\n",
    "    end_date = datetime.datetime(2020,12,1)\n",
    "    \n",
    "    # 1. datetime 형식 변환\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], format = \"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    # 2. 2020.11.1 ~ 2020.11.30까지의 데이터만 추출\n",
    "    df = df[(df.time >= start_date) & (df.time < end_date)]\n",
    "    \n",
    "    \n",
    "    # 3. 일자 데이터 추출\n",
    "    df[\"day\"] = list(map(lambda x: x.day, df.time))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality = time_processing(train_quality)\n",
    "train_error = time_processing(train_error)\n",
    "train_problem = time_processing(train_problem)\n",
    "\n",
    "test_quality = time_processing(test_quality)\n",
    "test_error = time_processing(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_quality's time period : 2020-11-01 00:00:00 ~ 2020-11-30 23:40:00\n",
      "train_error's time period : 2020-11-01 00:00:00 ~ 2020-11-30 23:59:59\n",
      "train_problem's time period : 2020-11-01 00:00:00 ~ 2020-11-30 23:00:00\n",
      "test_quality's time period : 2020-11-01 00:00:00 ~ 2020-11-30 23:40:00\n",
      "test_error's time period : 2020-11-01 00:00:00 ~ 2020-11-30 23:59:59\n"
     ]
    }
   ],
   "source": [
    "# 시간 오래걸림\n",
    "train_quality_period = (min(train_quality.time), max(train_quality.time))\n",
    "train_error_period = (min(train_error.time), max(train_error.time))\n",
    "problem_period = (min(train_problem.time), max(train_problem.time))\n",
    "test_quality_period = (min(test_quality.time), max(test_quality.time))\n",
    "test_error_period = (min(test_error.time), max(test_error.time))\n",
    "\n",
    "\n",
    "print(\"train_quality's time period :\", train_quality_period[0],\"~\",train_quality_period[1]) # quality's period : 2020-10-31 23:50:00 ~ 2020-11-30 23:40:00\n",
    "print(\"train_error's time period :\", train_error_period[0],\"~\",train_error_period[1])       # error's period : 2020-10-31 23:59:00 ~ 2020-12-02 18:51:00\n",
    "print(\"train_problem's time period :\", problem_period[0],\"~\",problem_period[1])             # problem's period : 2020-11-01 00:00:00 ~ 2020-11-30 23:00:00\n",
    "print(\"test_quality's time period :\", test_quality_period[0],\"~\",test_quality_period[1])    # quality's period : 2020-10-31 23:50:00 ~ 2020-11-30 23:40:00\n",
    "print(\"test_error's time period :\", test_error_period[0],\"~\",test_error_period[1])          # error's period : 2020-10-31 23:59:00 ~ 2020-12-02 18:51:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          datetime64[ns]\n",
       "user_id                int64\n",
       "fwver                 object\n",
       "quality_0            float64\n",
       "quality_1              int64\n",
       "quality_2            float64\n",
       "quality_3              int64\n",
       "quality_4              int64\n",
       "quality_5             object\n",
       "quality_6              int64\n",
       "quality_7             object\n",
       "quality_8             object\n",
       "quality_9             object\n",
       "quality_10            object\n",
       "quality_11             int64\n",
       "quality_12             int64\n",
       "day                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              int64\n",
       "time        datetime64[ns]\n",
       "model_nm            object\n",
       "fwver               object\n",
       "errtype              int64\n",
       "errcode             object\n",
       "day                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             int64\n",
       "time       datetime64[ns]\n",
       "day                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_problem.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          datetime64[ns]\n",
       "user_id                int64\n",
       "fwver                 object\n",
       "quality_0            float64\n",
       "quality_1             object\n",
       "quality_2            float64\n",
       "quality_3              int64\n",
       "quality_4              int64\n",
       "quality_5             object\n",
       "quality_6              int64\n",
       "quality_7             object\n",
       "quality_8             object\n",
       "quality_9             object\n",
       "quality_10            object\n",
       "quality_11             int64\n",
       "quality_12             int64\n",
       "day                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              int64\n",
       "time        datetime64[ns]\n",
       "model_nm            object\n",
       "fwver               object\n",
       "errtype              int64\n",
       "errcode             object\n",
       "day                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Quality data type reform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2num(x):\n",
    "    # (,)( )과 같은 불필요한 데이터 정제\n",
    "    if str(x) == \"nan\":\n",
    "        return None\n",
    "    \n",
    "    x = re.sub(r\"[^0-9]+\", '', str(x))\n",
    "    if x =='':\n",
    "        return 0\n",
    "    else:\n",
    "        return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_data_reform(df):\n",
    "    tmp_df = df.copy()\n",
    "    qual_cols = train_quality.columns[train_quality.columns.str.contains(\"quality\")]\n",
    "    for col in qual_cols:\n",
    "        tmp_df[col] = tmp_df[col].apply(string2num)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality = quality_data_reform(train_quality)\n",
    "test_quality = quality_data_reform(test_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          datetime64[ns]\n",
       "user_id                int64\n",
       "fwver                 object\n",
       "quality_0            float64\n",
       "quality_1              int64\n",
       "quality_2            float64\n",
       "quality_3              int64\n",
       "quality_4              int64\n",
       "quality_5            float64\n",
       "quality_6              int64\n",
       "quality_7              int64\n",
       "quality_8              int64\n",
       "quality_9              int64\n",
       "quality_10             int64\n",
       "quality_11             int64\n",
       "quality_12             int64\n",
       "day                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          datetime64[ns]\n",
       "user_id                int64\n",
       "fwver                 object\n",
       "quality_0            float64\n",
       "quality_1            float64\n",
       "quality_2            float64\n",
       "quality_3              int64\n",
       "quality_4              int64\n",
       "quality_5            float64\n",
       "quality_6              int64\n",
       "quality_7              int64\n",
       "quality_8              int64\n",
       "quality_9              int64\n",
       "quality_10             int64\n",
       "quality_11             int64\n",
       "quality_12             int64\n",
       "day                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time               0\n",
       "user_id            0\n",
       "fwver          40068\n",
       "quality_0     144420\n",
       "quality_1          0\n",
       "quality_2      40101\n",
       "quality_3          0\n",
       "quality_4          0\n",
       "quality_5         20\n",
       "quality_6          0\n",
       "quality_7          0\n",
       "quality_8          0\n",
       "quality_9          0\n",
       "quality_10         0\n",
       "quality_11         0\n",
       "quality_12         0\n",
       "day                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time               0\n",
       "user_id            0\n",
       "fwver          22764\n",
       "quality_0     106584\n",
       "quality_1         11\n",
       "quality_2      21115\n",
       "quality_3          0\n",
       "quality_4          0\n",
       "quality_5         44\n",
       "quality_6          0\n",
       "quality_7          0\n",
       "quality_8          0\n",
       "quality_9          0\n",
       "quality_10         0\n",
       "quality_11         0\n",
       "quality_12         0\n",
       "day                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5. Null check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time               0\n",
       "user_id            0\n",
       "fwver          40068\n",
       "quality_0     144420\n",
       "quality_1          0\n",
       "quality_2      40101\n",
       "quality_3          0\n",
       "quality_4          0\n",
       "quality_5         20\n",
       "quality_6          0\n",
       "quality_7          0\n",
       "quality_8          0\n",
       "quality_9          0\n",
       "quality_10         0\n",
       "quality_11         0\n",
       "quality_12         0\n",
       "day                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time               0\n",
       "user_id            0\n",
       "fwver          22764\n",
       "quality_0     106584\n",
       "quality_1         11\n",
       "quality_2      21115\n",
       "quality_3          0\n",
       "quality_4          0\n",
       "quality_5         44\n",
       "quality_6          0\n",
       "quality_7          0\n",
       "quality_8          0\n",
       "quality_9          0\n",
       "quality_10         0\n",
       "quality_11         0\n",
       "quality_12         0\n",
       "day                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "time        0\n",
       "model_nm    0\n",
       "fwver       0\n",
       "errtype     0\n",
       "errcode     1\n",
       "day         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "time        0\n",
       "model_nm    0\n",
       "fwver       0\n",
       "errtype     0\n",
       "errcode     4\n",
       "day         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    0\n",
       "time       0\n",
       "day        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_problem.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-6. Null Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) train_quality 내 fwver null 채우기 \n",
    "* Main IDEA : (quality.user_id -> error.user_id)를 추적해 error데이터에서 사용중인 fwver를 가져온다.\n",
    "    1. quality.fwver에서 null값을 가지는 user_id 리스트 생성\n",
    "    2. error.user_id가 가지는 각 fwver 빈도수 체크\n",
    "    3. 가장 빈도수가 많은 fwver로 quality.fwver에 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_index_by_user(df, uid, col_name):\n",
    "    df = df[df.user_id == uid]\n",
    "    return df[df[col_name].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_fwver_null_processing(raw_quality, raw_error):\n",
    "    df = raw_quality.copy()\n",
    "    fwver_null_uids = df[df.fwver.isnull()].user_id.unique()\n",
    "    tmp_err = raw_error[[\"user_id\",\"fwver\"]]\n",
    "    \n",
    "    for uid in fwver_null_uids:\n",
    "        grouped_err = tmp_err[tmp_err.user_id == uid].groupby(\"fwver\").count()\n",
    "        try:\n",
    "            fw_ver = grouped_err.sort_values(\"user_id\", ascending = False).iloc[0].name\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        null_idx = get_null_index_by_user(df, uid, \"fwver\")\n",
    "        df.loc[null_idx,\"fwver\"] = fw_ver\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality = quality_fwver_null_processing(train_quality, train_error)\n",
    "test_quality = quality_fwver_null_processing(test_quality, test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time               0\n",
       "user_id            0\n",
       "fwver              0\n",
       "quality_0     144420\n",
       "quality_1          0\n",
       "quality_2      40101\n",
       "quality_3          0\n",
       "quality_4          0\n",
       "quality_5         20\n",
       "quality_6          0\n",
       "quality_7          0\n",
       "quality_8          0\n",
       "quality_9          0\n",
       "quality_10         0\n",
       "quality_11         0\n",
       "quality_12         0\n",
       "day                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time               0\n",
       "user_id            0\n",
       "fwver            444\n",
       "quality_0     106584\n",
       "quality_1         11\n",
       "quality_2      21115\n",
       "quality_3          0\n",
       "quality_4          0\n",
       "quality_5         44\n",
       "quality_6          0\n",
       "quality_7          0\n",
       "quality_8          0\n",
       "quality_9          0\n",
       "quality_10         0\n",
       "quality_11         0\n",
       "quality_12         0\n",
       "day                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) train_quality 내 각종 quality변수 null 채우기\n",
    ">* Main Idea : fwver에 따라 quality의 분포가 대략적으로 결정된다. \n",
    ">* 따라서 동 fwver의 다른 quality 데이터에서 샘플을 추출하는 방식으로 기존의 데이터 분포를 모방 할 계획  \n",
    ">\n",
    ">\n",
    ">* EDA를 통해 데이터를 훑어본 결과, quality데이터가 null인 경우는 두가지가 존재한다.\n",
    ">     1. 특정 quality가 특정 fwver에 대해 통째로 null인 경우\n",
    ">     2. 특정 fwver에 대해 특정 quality가 통째로 null이 이난 경우\n",
    ">     \n",
    ">     \n",
    ">* 이에 따라 위 조건에 따라 다른 처리가 필요하다. 가령 1의 경우 전부 0으로 만들어주는 식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # 과정을 반복해도 동일한 결과가 나오도록하기 위해 seed 0으로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_null_processing(raw_df):\n",
    "    df = raw_df.copy()\n",
    "    null_exist_cols = df.columns[df.isnull().sum() > 0].values\n",
    "    \n",
    "    for col in null_exist_cols:\n",
    "        fw_vers = df[df[col].isnull()].fwver.unique()\n",
    "        \n",
    "        for fw_ver in fw_vers:\n",
    "            table = df[(df.fwver == fw_ver) & (df[col].notnull())]\n",
    "            choice_pool = table[col].values\n",
    "            null_idxs = df[(df.fwver == fw_ver) & (df[col].isnull())].index\n",
    "            \n",
    "            choice_size = len(null_idxs)\n",
    "            \n",
    "            if len(choice_pool) == 0:\n",
    "                choice_pool = [0]\n",
    "            \n",
    "            df.loc[null_idxs, col] = np.random.choice(choice_pool, choice_size)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality = quality_null_processing(train_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quality = quality_null_processing(test_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          0\n",
       "user_id       0\n",
       "fwver         0\n",
       "quality_0     0\n",
       "quality_1     0\n",
       "quality_2     0\n",
       "quality_3     0\n",
       "quality_4     0\n",
       "quality_5     0\n",
       "quality_6     0\n",
       "quality_7     0\n",
       "quality_8     0\n",
       "quality_9     0\n",
       "quality_10    0\n",
       "quality_11    0\n",
       "quality_12    0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time            0\n",
       "user_id         0\n",
       "fwver         444\n",
       "quality_0     444\n",
       "quality_1       0\n",
       "quality_2     444\n",
       "quality_3       0\n",
       "quality_4       0\n",
       "quality_5       0\n",
       "quality_6       0\n",
       "quality_7       0\n",
       "quality_8       0\n",
       "quality_9       0\n",
       "quality_10      0\n",
       "quality_11      0\n",
       "quality_12      0\n",
       "day             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test_quality에는 error에도 존재하지 않는 fwver이 있었다.\n",
    "* 따라서 해당 fwver에 대한 결측값 대체는 불가능하므로 삭제해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quality = test_quality.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          0\n",
       "user_id       0\n",
       "fwver         0\n",
       "quality_0     0\n",
       "quality_1     0\n",
       "quality_2     0\n",
       "quality_3     0\n",
       "quality_4     0\n",
       "quality_5     0\n",
       "quality_6     0\n",
       "quality_7     0\n",
       "quality_8     0\n",
       "quality_9     0\n",
       "quality_10    0\n",
       "quality_11    0\n",
       "quality_12    0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-7. Target data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = np.zeros(15000, dtype = int)\n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "min_user_id = 10000\n",
    "\n",
    "problem[train_problem.user_id.unique() - min_user_id] = 1 \n",
    "problem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-8. Qaulity data describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_3</th>\n",
       "      <th>quality_4</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>828408.000000</td>\n",
       "      <td>8.284080e+05</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>8.284080e+05</td>\n",
       "      <td>828408.0</td>\n",
       "      <td>828408.0</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>8.284080e+05</td>\n",
       "      <td>828408.000000</td>\n",
       "      <td>828408.00000</td>\n",
       "      <td>828408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17574.629357</td>\n",
       "      <td>3.743176e+01</td>\n",
       "      <td>0.199083</td>\n",
       "      <td>4.878499e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.911366</td>\n",
       "      <td>2.414512</td>\n",
       "      <td>26.750572</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>56.358925</td>\n",
       "      <td>8.967144e+02</td>\n",
       "      <td>0.189299</td>\n",
       "      <td>0.04589</td>\n",
       "      <td>15.308109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4374.135400</td>\n",
       "      <td>4.356004e+03</td>\n",
       "      <td>0.685093</td>\n",
       "      <td>5.719742e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2278.917033</td>\n",
       "      <td>32.674342</td>\n",
       "      <td>317.915952</td>\n",
       "      <td>5.154911</td>\n",
       "      <td>3280.777658</td>\n",
       "      <td>1.652317e+04</td>\n",
       "      <td>0.394198</td>\n",
       "      <td>0.30249</td>\n",
       "      <td>8.762233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13685.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17597.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21424.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24997.000000</td>\n",
       "      <td>1.576670e+06</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>1.918590e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637385.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>1317.000000</td>\n",
       "      <td>397424.000000</td>\n",
       "      <td>1.910175e+06</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id     quality_0      quality_1     quality_2  quality_3  \\\n",
       "count  828408.000000  8.284080e+05  828408.000000  8.284080e+05   828408.0   \n",
       "mean    17574.629357  3.743176e+01       0.199083  4.878499e+01        0.0   \n",
       "std      4374.135400  4.356004e+03       0.685093  5.719742e+03        0.0   \n",
       "min     10000.000000  0.000000e+00       0.000000  0.000000e+00        0.0   \n",
       "25%     13685.000000  0.000000e+00       0.000000  0.000000e+00        0.0   \n",
       "50%     17597.000000  0.000000e+00       0.000000  0.000000e+00        0.0   \n",
       "75%     21424.000000  0.000000e+00       0.000000  0.000000e+00        0.0   \n",
       "max     24997.000000  1.576670e+06     171.000000  1.918590e+06        0.0   \n",
       "\n",
       "       quality_4      quality_5      quality_6      quality_7      quality_8  \\\n",
       "count   828408.0  828408.000000  828408.000000  828408.000000  828408.000000   \n",
       "mean         0.0      74.911366       2.414512      26.750572       0.163716   \n",
       "std          0.0    2278.917033      32.674342     317.915952       5.154911   \n",
       "min          0.0       0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.0       0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.0       0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.0       1.000000       0.000000       0.000000       0.000000   \n",
       "max          0.0  637385.000000     600.000000    7200.000000    1317.000000   \n",
       "\n",
       "           quality_9    quality_10     quality_11    quality_12            day  \n",
       "count  828408.000000  8.284080e+05  828408.000000  828408.00000  828408.000000  \n",
       "mean       56.358925  8.967144e+02       0.189299       0.04589      15.308109  \n",
       "std      3280.777658  1.652317e+04       0.394198       0.30249       8.762233  \n",
       "min         0.000000  0.000000e+00       0.000000       0.00000       1.000000  \n",
       "25%         0.000000  3.000000e+00       0.000000       0.00000       8.000000  \n",
       "50%         0.000000  6.000000e+00       0.000000       0.00000      15.000000  \n",
       "75%         0.000000  3.900000e+01       0.000000       0.00000      23.000000  \n",
       "max    397424.000000  1.910175e+06      14.000000      14.00000      30.000000  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quality.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_3</th>\n",
       "      <th>quality_4</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>7.473960e+05</td>\n",
       "      <td>747396.0</td>\n",
       "      <td>747396.0</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>7.473960e+05</td>\n",
       "      <td>7.473960e+05</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "      <td>747396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37414.627603</td>\n",
       "      <td>21.425924</td>\n",
       "      <td>0.223025</td>\n",
       "      <td>6.480222e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.846492</td>\n",
       "      <td>2.499269</td>\n",
       "      <td>27.716359</td>\n",
       "      <td>0.400751</td>\n",
       "      <td>7.556544e+01</td>\n",
       "      <td>7.878810e+02</td>\n",
       "      <td>0.193025</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>15.260328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4259.202732</td>\n",
       "      <td>2027.988912</td>\n",
       "      <td>12.137486</td>\n",
       "      <td>1.182668e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1879.186953</td>\n",
       "      <td>33.638400</td>\n",
       "      <td>324.811143</td>\n",
       "      <td>43.424185</td>\n",
       "      <td>8.766098e+03</td>\n",
       "      <td>1.757952e+04</td>\n",
       "      <td>0.398132</td>\n",
       "      <td>0.337904</td>\n",
       "      <td>8.748296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33783.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37282.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41064.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44997.000000</td>\n",
       "      <td>930380.000000</td>\n",
       "      <td>10452.000000</td>\n",
       "      <td>6.366190e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156398.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>10452.000000</td>\n",
       "      <td>1.954316e+06</td>\n",
       "      <td>1.172849e+06</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id      quality_0      quality_1     quality_2  quality_3  \\\n",
       "count  747396.000000  747396.000000  747396.000000  7.473960e+05   747396.0   \n",
       "mean    37414.627603      21.425924       0.223025  6.480222e+01        0.0   \n",
       "std      4259.202732    2027.988912      12.137486  1.182668e+04        0.0   \n",
       "min     30000.000000       0.000000       0.000000  0.000000e+00        0.0   \n",
       "25%     33783.000000       0.000000       0.000000  0.000000e+00        0.0   \n",
       "50%     37282.000000       0.000000       0.000000  0.000000e+00        0.0   \n",
       "75%     41064.000000       0.000000       0.000000  0.000000e+00        0.0   \n",
       "max     44997.000000  930380.000000   10452.000000  6.366190e+06        0.0   \n",
       "\n",
       "       quality_4      quality_5      quality_6      quality_7      quality_8  \\\n",
       "count   747396.0  747396.000000  747396.000000  747396.000000  747396.000000   \n",
       "mean         0.0      65.846492       2.499269      27.716359       0.400751   \n",
       "std          0.0    1879.186953      33.638400     324.811143      43.424185   \n",
       "min          0.0       0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.0       0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.0       0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.0       1.000000       0.000000       0.000000       0.000000   \n",
       "max          0.0  156398.000000     600.000000    7200.000000   10452.000000   \n",
       "\n",
       "          quality_9    quality_10     quality_11     quality_12            day  \n",
       "count  7.473960e+05  7.473960e+05  747396.000000  747396.000000  747396.000000  \n",
       "mean   7.556544e+01  7.878810e+02       0.193025       0.040589      15.260328  \n",
       "std    8.766098e+03  1.757952e+04       0.398132       0.337904       8.748296  \n",
       "min    0.000000e+00  0.000000e+00       0.000000       0.000000       1.000000  \n",
       "25%    0.000000e+00  3.000000e+00       0.000000       0.000000       8.000000  \n",
       "50%    0.000000e+00  5.000000e+00       0.000000       0.000000      15.000000  \n",
       "75%    0.000000e+00  2.500000e+01       0.000000       0.000000      23.000000  \n",
       "max    1.954316e+06  1.172849e+06      17.000000      19.000000      30.000000  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quality.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* quality_3, quality_4는 모든 데이터가 0임을 확인\n",
    "    * 분포확인이 불가능해 problem예측에 불필요한 데이터 -> **제거**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality = train_quality.drop([\"quality_3\",\"quality_4\"], axis = 1)\n",
    "test_quality = test_quality.drop([\"quality_3\",\"quality_4\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-9. Feature engineering (user별 요약)\n",
    "> ### 1. Quality data **(93 columns)**\n",
    ">> 1. quality_3, quality_4 제거\n",
    ">>> * quality_3, quality_4는 모든 데이터가 0임을 확인\n",
    ">>> * 분포확인이 불가능해 problem예측에 불필요한 데이터 -> **제거**\n",
    ">> 1. 중복행 제거\n",
    ">>> * 동일 user, 동일 시간, quality_0 ~ quality_12 까지 모두 일치하는 행이 약 55만개 (전체행 82만개)\n",
    ">>> * 모델의 편향을 줄 수 있다 생각하여 중복되는 행을 제거\n",
    ">> 2. 유저별 quality 지표 변경횟수 집계 **(quality_change_ : 5열)**\n",
    ">>> * (1)에서 중복행을 제거해준것을 토대로 유저별로 1일간 quality가 변경되었던 횟수를 count하여 나열 ([유저, 일자]로 groupby)\n",
    ">>> * 유저별로 quality 변경횟수를 집계(합계, 평균값, 분산, 최대값, count)\n",
    ">> 3. 유저별 quality 지표 (평균, Q1, 중앙값, Q3, 분산, 최대값, 최소값, 범위) 추출 **(quality_N_ : 88열)**\n",
    ">>> * 각 quality 데이터를 유저별로 요약하여 지도학습을 위함\n",
    ">>> * quality 데이터가 좌측으로 심하게 치우친 분포이므로 mean 대신 median 사용\n",
    "\n",
    "> ### 2. Error data **(79 columns)**\n",
    ">> 1. 일별 error 발생횟수 열 생성 **(err_at_N : 30열)**\n",
    ">>> * ex) 11월 N일에 user_id가 10000인 user에게 발생된 error의 횟수\n",
    ">> 2. 유저별 errtype 발생횟수 **(errtype_N : 42열)**\n",
    ">>> * error type 갯수가 42개인것이 확인됨\n",
    ">>> * 각 error type 별 갯수로 고객의 불만을 예측 하고자 함\n",
    ">> 3. fwver 변경 로그 추출 **(fwver_N : 4열)**\n",
    ">>> * 유저별 fwver변경은 최대 3회가 일어난다.\n",
    ">>> * fwver 변경시 고객의 문제가 제기 되는것을 확인 할 수 있었음\n",
    ">> 4. model 변경 로그 추출 **(model_nm_N : 3열)**\n",
    ">>> * model 변경시 고객의 문제가 제기 되는것을 확인 할 수 있었음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Qaulity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1(x):\n",
    "    return np.percentile(x,25)\n",
    "\n",
    "def Q3(x):\n",
    "    return np.percentile(x,75)\n",
    "\n",
    "def data_range(x):\n",
    "    return max(x) - min(x)\n",
    "\n",
    "def make_quality(quality_data):\n",
    "    # quality 3,4 제거\n",
    "    if \"quality_3\" in quality_data.columns:\n",
    "        quality_data = quality_data.drop([\"quality_3\",\"quality_4\"], axis = 1)\n",
    "    qual_cols = quality_data.columns[quality_data.columns.str.contains(\"quality\")]\n",
    "    \n",
    "    # 1. 중복제거\n",
    "    unique_train_quality = quality_data.drop_duplicates()\n",
    "\n",
    "    # 2. 일별 quality 변화 횟수 집계\n",
    "    quality_change_in_day = unique_train_quality[[\"user_id\",\"day\",\"time\"]].groupby([\"user_id\",\"day\"]).count()\n",
    "    quality_change_in_day.columns = [\"quality_change\"]\n",
    "    quality_change_in_day = quality_change_in_day.reset_index()\n",
    "\n",
    "    summary_quality_count_by_day = quality_change_in_day[[\"user_id\",\"quality_change\"]].groupby(\"user_id\").agg([\"sum\",\"mean\",\"std\",\"max\",\"count\"])\n",
    "    summary_quality_count_by_day = summary_quality_count_by_day.fillna(0)\n",
    "    new_cols = [\"_\".join(col) for col in summary_quality_count_by_day.columns]\n",
    "    summary_quality_count_by_day.columns = new_cols\n",
    "    \n",
    "    # 3. user별 quality 특성 집계\n",
    "    idx_col = [\"user_id\"] + list(qual_cols)\n",
    "    \n",
    "    quality_summary = unique_train_quality[idx_col].groupby(\"user_id\").agg([\"mean\",Q1,\"median\",Q3,\"std\",\"max\",\"min\",data_range])\n",
    "    new_cols = [\"_\".join(col) for col in quality_summary.columns]\n",
    "    quality_summary.columns = new_cols\n",
    "    \n",
    "    # 4. 생성된 데이터셋 병합\n",
    "    final_df = summary_quality_count_by_day\n",
    "    final_df = final_df.merge(quality_summary, left_index = True, right_index = True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_quality = make_quality(train_quality).reset_index()\n",
    "preprocessed_test_quality = make_quality(test_quality).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Error data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_change_log(tmp_df, min_user, max_user, min_types):\n",
    "    tmp_df = tmp_df.sort_values(\"user_id\")\n",
    "    user_len = max_user - min_user\n",
    "    tmp_arr = np.zeros((user_len,min_types), dtype = int).astype(\"str\")\n",
    "    \n",
    "    before_uid = None\n",
    "    i = 0\n",
    "    for user_id, value in tmp_df.values:\n",
    "        if user_id == before_uid:\n",
    "            i += 1\n",
    "            if i >= min_types: continue\n",
    "            tmp_arr[user_id - min_user, i] = value\n",
    "        else:\n",
    "            i = 0\n",
    "            tmp_arr[user_id - min_user, i] = value\n",
    "        before_uid = user_id\n",
    "    \n",
    "    tmp_df = pd.DataFrame(tmp_arr,index = np.arange(min_user,max_user))\n",
    "    return tmp_df\n",
    "\n",
    "def error_preprocess_X(error_data, train = \"train\"):\n",
    "    min_user = 30000\n",
    "    max_user = 44999\n",
    "    if train == \"train\":\n",
    "        min_user = 10000\n",
    "        max_user = 25000\n",
    "    \n",
    "    # 1. user별, 일별 error 발생 횟수\n",
    "    user_err_count = error_data[[\"user_id\",\"day\",\"time\"]].groupby([\"user_id\",\"day\"]).count()\n",
    "    user_err_count.columns = [\"err_at\"]\n",
    "    user_err_count = user_err_count.unstack(level = -1, fill_value = 0)\n",
    "\n",
    "    err_count_cols = user_err_count.columns.values\n",
    "    err_count_cols = list(map(lambda x: x[0] + \"_\" + str(x[1]), err_count_cols))\n",
    "    user_err_count.columns = err_count_cols\n",
    "    \n",
    "    # 2. groupby 연산을 통해 user, errtype별 횟수 생성\n",
    "    user_day_errtype = error_data[[\"user_id\",\"errtype\",\"time\"]].groupby([\"user_id\",\"errtype\"]).count()\n",
    "    user_day_errtype.columns = [\"errtype\"]\n",
    "    user_day_errtype = user_day_errtype.unstack(level = -1, fill_value = 0)\n",
    "\n",
    "    errtype_cols = user_day_errtype.columns.values\n",
    "    errtype_cols = list(map(lambda x: x[0] + \"_\" + str(x[1]), errtype_cols))\n",
    "\n",
    "    user_day_errtype.columns = errtype_cols\n",
    "\n",
    "    # 3. fwver 변화과정 데이터 생성\n",
    "    tmp_df = error_data[[\"user_id\",\"fwver\"]].drop_duplicates()\n",
    "    fwver_change_df = make_change_log(tmp_df, min_user, max_user, 4).reset_index()\n",
    "    \n",
    "    fwver_change_df.columns = [\"user_id\",\"fwver_1\",\"fwver_2\",\"fwver_3\",\"fwver_4\"]\n",
    "    \n",
    "    # 4. model 변화과정 데이터 생성\n",
    "    tmp_df = error_data[[\"user_id\",\"model_nm\"]].drop_duplicates()\n",
    "    model_change_df = make_change_log(tmp_df, min_user, max_user, 3).reset_index()\n",
    "    \n",
    "    model_change_df.columns = [\"user_id\",\"model_nm_1\",\"model_nm_2\",\"model_nm_3\"]\n",
    "    \n",
    "    # 5. 데이터 병합\n",
    "    user_errtype = user_day_errtype.copy()\n",
    "    \n",
    "    merged_1 = pd.merge(user_err_count, user_errtype, left_index = True, right_index = True).reset_index()\n",
    "    merged_2 = pd.merge(fwver_change_df, model_change_df, on = \"user_id\")\n",
    "    \n",
    "    fin_data = pd.merge(merged_1, merged_2, on = \"user_id\")\n",
    "    return fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_processing(raw_df):\n",
    "    df = raw_df.copy()\n",
    "    label_enc = LabelEncoder()\n",
    "    object_cols = df.columns[df.dtypes == \"object\"]\n",
    "\n",
    "    for col in object_cols:\n",
    "        df[col] = label_enc.fit_transform(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_error = error_preprocess_X(train_error, \"train\")\n",
    "preprocessed_test_error = error_preprocess_X(test_error,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_error = object_processing(preprocessed_train_error)\n",
    "preprocessed_test_error = object_processing(preprocessed_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Problem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = np.zeros(15000)\n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "problem[train_problem.user_id.unique()-10000] = 1 \n",
    "problem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. merge (quality & error & problem) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(preprocessed_train_error, preprocessed_train_quality, how = \"left\", on = \"user_id\",)\n",
    "test_data = pd.merge(preprocessed_test_error, preprocessed_test_quality, how = \"left\", on = \"user_id\")\n",
    "\n",
    "train_data[\"target\"] = problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-9. Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>err_at_1</th>\n",
       "      <th>err_at_2</th>\n",
       "      <th>err_at_3</th>\n",
       "      <th>err_at_4</th>\n",
       "      <th>err_at_5</th>\n",
       "      <th>err_at_6</th>\n",
       "      <th>err_at_7</th>\n",
       "      <th>err_at_8</th>\n",
       "      <th>err_at_9</th>\n",
       "      <th>...</th>\n",
       "      <th>quality_11_data_range</th>\n",
       "      <th>quality_12_mean</th>\n",
       "      <th>quality_12_Q1</th>\n",
       "      <th>quality_12_median</th>\n",
       "      <th>quality_12_Q3</th>\n",
       "      <th>quality_12_std</th>\n",
       "      <th>quality_12_max</th>\n",
       "      <th>quality_12_min</th>\n",
       "      <th>quality_12_data_range</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  err_at_1  err_at_2  err_at_3  err_at_4  err_at_5  err_at_6  \\\n",
       "0    10000        11         9        18         5        10         9   \n",
       "1    10001        11        50        29        48        42        29   \n",
       "2    10002        10        13        13        15         9         8   \n",
       "3    10003         9        14        10         5        16         5   \n",
       "4    10004        25        21        49        28        11        28   \n",
       "\n",
       "   err_at_7  err_at_8  err_at_9  ...  quality_11_data_range  quality_12_mean  \\\n",
       "0        20         7         5  ...                    0.0              0.0   \n",
       "1        13        24        53  ...                    NaN              NaN   \n",
       "2        17        11        12  ...                    1.0              0.0   \n",
       "3         2        11         5  ...                    NaN              NaN   \n",
       "4        18        29        20  ...                    1.0              0.0   \n",
       "\n",
       "   quality_12_Q1  quality_12_median  quality_12_Q3  quality_12_std  \\\n",
       "0            0.0                0.0            0.0             0.0   \n",
       "1            NaN                NaN            NaN             NaN   \n",
       "2            0.0                0.0            0.0             0.0   \n",
       "3            NaN                NaN            NaN             NaN   \n",
       "4            0.0                0.0            0.0             0.0   \n",
       "\n",
       "   quality_12_max  quality_12_min  quality_12_data_range  target  \n",
       "0             0.0             0.0                    0.0     0.0  \n",
       "1             NaN             NaN                    NaN     1.0  \n",
       "2             0.0             0.0                    0.0     0.0  \n",
       "3             NaN             NaN                    NaN     0.0  \n",
       "4             0.0             0.0                    0.0     1.0  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>err_at_1</th>\n",
       "      <th>err_at_2</th>\n",
       "      <th>err_at_3</th>\n",
       "      <th>err_at_4</th>\n",
       "      <th>err_at_5</th>\n",
       "      <th>err_at_6</th>\n",
       "      <th>err_at_7</th>\n",
       "      <th>err_at_8</th>\n",
       "      <th>err_at_9</th>\n",
       "      <th>...</th>\n",
       "      <th>quality_11_min</th>\n",
       "      <th>quality_11_data_range</th>\n",
       "      <th>quality_12_mean</th>\n",
       "      <th>quality_12_Q1</th>\n",
       "      <th>quality_12_median</th>\n",
       "      <th>quality_12_Q3</th>\n",
       "      <th>quality_12_std</th>\n",
       "      <th>quality_12_max</th>\n",
       "      <th>quality_12_min</th>\n",
       "      <th>quality_12_data_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>82</td>\n",
       "      <td>808</td>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  err_at_1  err_at_2  err_at_3  err_at_4  err_at_5  err_at_6  \\\n",
       "0    30000        76         2         7         0        24        82   \n",
       "1    30001        13        18         5        17         4         2   \n",
       "2    30002        29        18        53        20        30        14   \n",
       "3    30003         6        11        10         6         4        10   \n",
       "4    30004        39        28        21        48         8        20   \n",
       "\n",
       "   err_at_7  err_at_8  err_at_9  ...  quality_11_min  quality_11_data_range  \\\n",
       "0       808        95         7  ...             0.0                    0.0   \n",
       "1        22        16         0  ...             0.0                    1.0   \n",
       "2        41        17        12  ...             0.0                    1.0   \n",
       "3         0        35        10  ...             0.0                    0.0   \n",
       "4        19        37        12  ...             0.0                    1.0   \n",
       "\n",
       "   quality_12_mean  quality_12_Q1  quality_12_median  quality_12_Q3  \\\n",
       "0              0.0            0.0                0.0            0.0   \n",
       "1              0.0            0.0                0.0            0.0   \n",
       "2              0.0            0.0                0.0            0.0   \n",
       "3              0.0            0.0                0.0            0.0   \n",
       "4              0.0            0.0                0.0            0.0   \n",
       "\n",
       "   quality_12_std  quality_12_max  quality_12_min  quality_12_data_range  \n",
       "0             0.0             0.0             0.0                    0.0  \n",
       "1             0.0             0.0             0.0                    0.0  \n",
       "2             0.0             0.0             0.0                    0.0  \n",
       "3             0.0             0.0             0.0                    0.0  \n",
       "4             0.0             0.0             0.0                    0.0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-10. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"./preprocessed/\"\n",
    "\n",
    "if \"preprocessed\" not in os.listdir():\n",
    "    os.makedirs(save_PATH)\n",
    "    print(\"`preprocessed` directory is generated!\")\n",
    "    \n",
    "train_data.to_csv(SAVE_PATH + \"train_data.csv\")\n",
    "test_data.to_csv(SAVE_PATH + \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------ 전처리된 데이터로 실행 시 여기부터 실행바랍니다. ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-11. Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"./preprocessed/\"\n",
    "\n",
    "train_data = pd.read_csv(SAVE_PATH + 'train_data.csv', index_col= 0)\n",
    "test_data = pd.read_csv(SAVE_PATH + 'test_data.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 172)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.array(train_data.drop('target',axis=1))\n",
    "train_y = np.array(train_data['target'])\n",
    "# del error, problem\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3633, number of negative: 8367\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23015\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302750 -> initscore=-0.834237\n",
      "[LightGBM] [Info] Start training from score -0.834237\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[20]\tvalid_0's auc: 0.817092\tvalid_0's pr_auc: 0.818193\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.817092\tvalid_0's pr_auc: 0.818193\n",
      "[LightGBM] [Info] Number of positive: 4828, number of negative: 7172\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402333 -> initscore=-0.395752\n",
      "[LightGBM] [Info] Start training from score -0.395752\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.792265\tvalid_0's pr_auc: 0.338419\n",
      "[LightGBM] [Info] Number of positive: 4718, number of negative: 7282\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23365\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393167 -> initscore=-0.434021\n",
      "[LightGBM] [Info] Start training from score -0.434021\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.769384\tvalid_0's pr_auc: 0.411307\n",
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 7456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23219\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378667 -> initscore=-0.495211\n",
      "[LightGBM] [Info] Start training from score -0.495211\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.813087\tvalid_0's pr_auc: 0.547176\n",
      "[LightGBM] [Info] Number of positive: 2277, number of negative: 9723\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22838\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.189750 -> initscore=-1.451635\n",
      "[LightGBM] [Info] Start training from score -1.451635\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.803232\tvalid_0's pr_auc: 0.975366\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#-------------------------------------------------------------------------------------\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.4\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'bagging_fraction' : '0.8',\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'max_depth' : 20,\n",
    "                'num_leaves' : 20,\n",
    "                'seed': 111\n",
    "    \n",
    "                }\n",
    "#-------------------------------------------------------------------------------------\n",
    "# 5 Kfold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_x):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_x[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 3\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7990120248430435\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_data)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55789716],\n",
       "       [0.30712053],\n",
       "       [0.31579017],\n",
       "       ...,\n",
       "       [0.34880219],\n",
       "       [0.56035812],\n",
       "       [0.3168421 ]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 제출파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.557897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.307121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.315790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.517555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.573848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>44994</td>\n",
       "      <td>0.307766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>44995</td>\n",
       "      <td>0.330342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>44996</td>\n",
       "      <td>0.348802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>44997</td>\n",
       "      <td>0.560358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>44998</td>\n",
       "      <td>0.316842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   problem\n",
       "0        30000  0.557897\n",
       "1        30001  0.307121\n",
       "2        30002  0.315790\n",
       "3        30003  0.517555\n",
       "4        30004  0.573848\n",
       "...        ...       ...\n",
       "14993    44994  0.307766\n",
       "14994    44995  0.330342\n",
       "14995    44996  0.348802\n",
       "14996    44997  0.560358\n",
       "14997    44998  0.316842\n",
       "\n",
       "[14999 rows x 2 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion = sample_submssion[sample_submssion['user_id']!=43262]\n",
    "\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "sample_submssion =  sample_submssion.append({'user_id' : 43262, 'problem' : 0.5},ignore_index=True)\n",
    "sample_submssion['user_id'] = sample_submssion['user_id'].astype(int)\n",
    "sample_submssion = sample_submssion.sort_values('user_id')\n",
    "\n",
    "sample_submssion.to_csv(\"sub.csv\", index = False)\n",
    "sample_submssion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
